[
["lecture-3-data-modeling-tidy-data.html", "Chapter 3 Lecture 3 - Data Modeling &amp; Tidy Data 3.1 Learning Objectives 3.2 Benefits of relational data systems 3.3 Data Organization 3.4 Multiple tables 3.5 Inconsistent observations 3.6 Inconsistent variables 3.7 Marginal sums and statistics 3.8 Good enough data modeling 3.9 Primary and Foreign Keys 3.10 Entity-Relationship Model (ER) 3.11 Merging data 3.12 Simple Guidelines for Effective Data 3.13 Data modeling assignment 3.14 Related resources", " Chapter 3 Lecture 3 - Data Modeling &amp; Tidy Data 3.1 Learning Objectives Understand basics of relational data models aka tidy data Learn how to design and create effective data tables 3.2 Benefits of relational data systems Powerful search and filtering Handle large, complex data sets Enforce data integrity Decrease errors from redundant updates 3.3 Data Organization 3.4 Multiple tables 3.5 Inconsistent observations 3.6 Inconsistent variables 3.7 Marginal sums and statistics 3.8 Good enough data modeling 3.8.1 Denormalized data Observations about different entities combined In the above example, each row has measurements about both the site at which observations occurred, as well as observations of two individuals of possibly different species found at that site. This is not normalized data. People often refer to this as wide format, because the observations are spread across a wide number of columns. Note that, should one encounter a new species in the survey, we wold have to add new columns to the table. This is difficult to analyze, understand, and maintain. 3.8.2 Tabular data Observations. A better way to model data is to organize the observations about each type of entity in its own table. This results in: Separate tables for each type of entity measured Each row represents a single observed entity Observations (rows) are all unique This is normalized data (aka tidy data) Variables. In addition, for normalized data, we expect the variables to be organized such that: All values in a column are of the same type All columns pertain to the same observed entity (e.g., row) Each column represents either an identifying variable or a measured variable Here’s an example of tidy (normalized) data in which the top table is the collection of observations about individuals of several species, and the bottom table are the observations containing properties of the sites at which the species occurred. Tidy datasets are easy to manipulate, model and visualise, and have a specific structure: each variable is a column each observation is a row each type of observational unit is a table. 3.9 Primary and Foreign Keys When one has normalized data, we often use unique identifiers to reference particular observations, which allows us to link across tables. Two types of identifiers are common within relational data: Primary Key: unique identifier for each observed entity, one per row Foreign Key: reference to a primary key in another table (linkage) For example, in the second table below, the site column is the primary key of that table, because it uniquely identifies each row of the table as a unique observation of a site. Inthe first table, however, the site column is a foreign key that references the primary key from the second table. This linkage tells us that the first height measurement for the DAPU observation occurred at the site with the name Taku. 3.10 Entity-Relationship Model (ER) An Entity-Relationship model allows us to compactly draw the structure of the tables in a relational database, including the primary and foreign keys in the tables. In the above model, one can see that each site in the SITES table must have one or more observations in the PLOTOBS table, whereas each PLOTOBS has one and only one SITE. 3.11 Merging data Frequently, analysis of data will require merging these separately managed tables back together. There are multiple ways to join the observations in two tables, based on how the rows of one table are merged with the rows of the other. When conceptualizing merges, one can think of two tables, one on the left and one on the right. The most common (and often useful) join is when you merge the subset of rows that have matches in both the left table and the right table: this is called an INNER JOIN. Other types of join are possible as well. A LEFT JOIN takes all of the rows from the left table, and merges on the data from matching rows in the right table. A RIGHT JOIN is the same, except that all of the rows from the right table are included with matching data from the left. Finally, a FULL OUTER JOIN includes all data from all rows in both tables (and is rarely practical). In the figure above, the blue regions show the set of rows that are included in the result. For the INNER join, the rows returned are all rows in A that have a matching row in B. 3.12 Simple Guidelines for Effective Data Design to add rows, not columns Each column one type Eliminate redundancy Uncorrected data file Header line Nonproprietary formats Descriptive names No spaces Borer et al. 2009. Some Simple Guidelines for Effective Data Management. Bulletin of the Ecological Society of America. 3.13 Data modeling assignment For this assignment you will be working with a tidied up version of a dataset from the Alaska Department of Fish and Game (ADF&amp;G) containing commercial salmon catch data from 1878-1997. The dataset and reference to the original source can be viewed at its public archive: https://knb.ecoinformatics.org/#view/df35b.304.2. That site includes metadata describing the full data set, including column definitions. Here’s the first catch table: And here’s the region_defs table: Draw an ER model for the tables Indicate the primary and foreign keys 3.14 Related resources Borer et al. 2009. Some Simple Guidelines for Effective Data Management. Bulletin of the Ecological Society of America. Software Carpentry SQL tutorial Tidy Data "]
]
